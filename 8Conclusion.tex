\chapter{Conclusions and Future Work}
\label{chapter:conclude}
In this thesis, we study the surface texture processing problem from the perspective of reconstruction, semantic and geometric understanding.

The surface texture and the scanned images can be converted to each other via rendering and reconstruction. The texture space is an important 2D parameterization space that is helpful for texture understanding including the semantics and the parameterization itself. Accordingly, we explore several problems related to texture processing. First, we reconstruct high-quality color texture of 3D surfaces in real environments captured by commodity 3D scanners. Then, we build a robust and scalable quadrangulation algorithm for seamless surface parameterization. We provide effective solutions for learning geometric and semantic information from the surface texture. Finally, we find a solution to train a network that predicts the canonical parameterization directly from color signals.

For texture reconstruction, we address the inconsistent color mapping problem in the scanning data using traditional color consistency optimization-based methods in \emph{3DLite}, where we propose to compensate all the artifacts by explicitly warping and stitching image fragments from low-quality RGB input data to achieve high-resolution, sharp surface textures. We jointly optimize the sparse and dense terms for accurate alignment. Observing that motion blur is a ubiquitous artifact in many video frames from the input, we select a single candidate frame for every local region of the 3D surface in order to balance the sharpness and boundary coherency.
From another perspective, we propose to learn a deep metric that tolerates these errors instead of removing them and jointly optimize it with the texture so that the learned metric guides the direction of the realistic textures optimization.

While an image-based convolution operator is an intermediate solution for texture feature extraction, we further explore the convolution directly applied in the texture space of the 3D surface.
%
We observe that the key challenge is to define a consistent canonical 2D parameterization space of the 3D surface for such a convolution operator to be applied.
%
This challenge is related to the seamless surface parameterization problem in the computational geometry community. While existing state-of-the-art methods treat it as a mixed-integer programming problem which is NP-hard to solve, we derive a simplified version which reduces the problem into a minimum cost flow problem with polynomial time complexity. Therefore, we achieve a quadrangulation algorithm called \emph{Quadriflow} which is robust and scalable.

Based on the parameterization, we propose \emph{TextureNet} as a neural network formed with a 2D convolution operator in the local tangent space given our canonical parametrization.
%
Our 2D convolution is efficient and handles high-resolution texture signals, which outperforms other less efficient dense 3D convolution operators in the task of 3D semantics understanding.

Finally, the geometric surface parametrization serves as not only a basis for 3D convolution operators to apply but also useful information that is highly-correlated and learnable from the color signals. With the existence of scanning data with aligned RGB images, we propose to render the pre-computed 3D canonical frames given the camera transformation to the input views and train a neural network (\emph{FrameNet}) to estimate them from the RGB images. With understanding the 3D canonical frames from RGB images, our network enables applications ranging from surface normal estimation, feature matching and augmented reality. 

\section{Future Vision}
In the future, several challenging problems related to our topics or methodologies deserve to be explored.

\paragraph*{Geometry Priors} Geometry is the basis for texture reconstruction. Therefore, it is desired to fit scans with high-quality geometry priors with small fitting errors. While we explored the primitive fitting and CAD replacement, geometry fitting errors can be further reduced with mesh deformation. Specifically, the task is to retrieve the best CAD model in the repository which achieves minimum fitting errors after deformation. For example, we~\cite{uy2020deformation} recently explore to embed the CAD models into a latent space with a siamese network~\cite{finn2017model} where small Mahalanobis distances imply small fitting errors with deformation. In the future, we can also explore to jointly optimize the deformation with the embedding so that we obtain a good deformation function and a fast retrieval scheme at the same time.

\paragraph*{Joint Shape and Texture Optimization} In \emph{3DLite}~\cite{huang20173dlite} we adopt explicit parametric optimization, where the 3D planes are estimated based on problematic geometry. Therefore, our fixed geometry prior is inaccurate and cannot be improved during texture optimization, where a joint optimization of texture and geometry can be explored in the future. Specifically, it is interesting to explore the best intermediate shape representation during optimization. While traditional geometry optimization requires pairwise sparse or dense alignment with the representation of the point cloud, other smoother or deeper representation can be better for joint optimization. For example, a signed distance field~\cite{curless1996volumetric} is a smoother median shape for joint shape alignment. Further, deep SDF~\cite{park2019deepsdf} represents a shape with an over-parameterized neural network, which can be extended by incorporating the texture field~\cite{oechsle2019texture}. It is promising to jointly optimize such an over-parameterized function and the camera observations to avoid local minimum and converge to high-quality textured shape.

\paragraph*{Adversarial Information Aggregation} In \emph{Adversarial Texture Optimization}~\cite{huang2020adversarial}, we jointly optimize the deep metric and the aggregation of color information in the texture. In the future, we can extend the method to deal with different types of information aggregation. In the multiview stereo reconstruction problem, depth can be potentially aggregated with our adversarial metric. 3D skeleton poses of human bodies or hands can also be potentially refined with multiview predictions. Further, The adversarial metric can also be potentially useful for higher-level understanding. For example, existing works utilize the 2D semantic understanding method for 3D understanding~\cite{dai20183dmv}, where we can incorporate our adversarial metric to enhance the improvement of the semantic aggregation. 

\paragraph*{Hierarchical and Scale-aware Surface Parameterization} In \emph{Quadriflow}~\cite{huang2018quadriflow}, we solve the surface parameterization problem given a fine-resolution mesh. In the future, our problem can be further extended in a hierarchical formulation where we solve parameterization with different levels of details. This could potentially form a better-structured quad layout, resulting in an even smaller number of square patches for texturing. In addition, while we assume uniform parameterization in our scenario for texture understanding, other applications require adaptive mesh resolutions in order to preserve local geometry details with minimum mesh size. In the future, we can incorporate the local scale into our energy to solve this problem.

\paragraph*{Texture Convolution} In \emph{TextureNet}~\cite{huang2018texturenet}, we applied the texture convolution for 3D semantic segmentation. We believe that texture convolution can be explored for many other tasks in the future. Since it is an intrinsic operator, it is potentially effective that require intrinsic features, including human body segmentation~\cite{maron2017convolutional} and non-rigid registration~\cite{litany2017deep}. Since image convolutions are effective for image generation and completion, it is promising to use texture convolution for surface texture generation and completion. Further, texture convolution can be incorporated to enhance texture reconstruction with our adversarial texture optimization~\cite{huang2020adversarial} in the future.

\paragraph*{Joint Tasks with 3D Frame} In \emph{FrameNet}~\cite{framenet}, we explore the joint estimation of 3D canonical frames with projected tangent directions in 2D images. We believe the joint task can be extended to incorporate many other geometry features. A typical example is to incorporate the depth estimation into our framework, where depth and normal information is geometrically correlated. At a higher level, the frame provides important local orientation information, which can be aggregated to provide hints for more global information including object-level poses, vanishing points or Manhattan directions prediction. The orientation can also be potentially fused into the SLAM system for robust camera tracking. Such problems are fundamental for robotic applications including environment exploration and hand grasping.
